

## introduction

rise of biosensing

rise of apps that let you share biosignals socially (apple watch, thumbkisses, heartgram) - in these apps, people, rather than algorithms, are supposed to interpret biosensory data

however, it's not well understood how people build interpretations around these data, or what mechanisms give rise to these interpretations. in general, the expressive capacity of biosignals is not well understood. <!-- for all these kickstarters trying to make sensor-driven applications, how people actually interpret data from sensors is poorly understood. in most applications (consider xx) we assume that suggestion plays a role. but, what is the role of the sensor itself? the cultural narratives around the body, etc...? -->

<!-- from coye email - eventually take from finished rebuttal ->

the old (good) idea is that people interpret sensor data contextualy, to produce social interpretations (a la consolvo’s work on loction sharing)

our new idea is that past work on “social biosensing” has missed this connection - pentland, slovak, bell - and, we argue, investigating this topic more deeply is crucial as mobile health, self trckers, …, push ubiquitous sensing further into the computational mainstream

### my thesis (slash "hunch")

biosignals can mediate interpsonal interactions in complex, highly contextual ways, and transmitting biosensor data between individuals causes socal outcomes that are far from obvious. the conclusion of past literature (biosignal sharing builds intimacy) only scratches the surface.

### my questions

1. when biosignals are transmitted between people who are interacting socially,
how does context shape the interpretations they build around these data?

2. what is the effect of the signal itself on these interpretations? what is the effect of its representation?

3. what are these signals 'worth' to other people? to what extent do people value these data (or not) in different settings?

### why this topic? why these questions?

what we're really studying here is the way people take SUGGESTIONS from ambiguous sensor data

- data from the body has a complex relationship to "our" world of social meaning

- we explore that relationship using social interactions to 'raise the stakes'

- and because self-reflective interpretations are realatively well-studied



## methods

<!-- lifted from CLTC proposal -->
I will perform controlled, lab-based experiments, as well as survey-based vignettes, in which subjects partake in risky, uncertain interactions with other people (e.g., the money they receive depends on their behavior). Subjects will be exposed, or not exposed, to a biosignal collected from their partner. By introducing signals such as GSR, heart rate and EEG into classic social- behavioral experimental paradigms (e.g., dictator game, iterated prisoner's dilemma game), or into vignette scenarios, we can begin to observe how the presence of biosignals affects social behavior, as compared to control conditions.
<!-- 
These studies will provide a limited, but useful starting point for understanding how, why, and when disclosure of biosignals might become relevant. We hope to shed light on how these signals are incorporated into our understandings of the moods, motivations, and goals of other people, which in turn will lay groundwork for a deeper understanding of how wearable data might become sensitive, or might lead to over-disclosure, in different settings and contexts.
 -->

### why these methods?

with our methods we can establish baseline behaviors relative too well-known findings from social psychology, giving us a better idea for how this information is integrated into a broader socail understanding

### outcomes 

broadly, i'm hoping these findings gesture toward a few interesting questions, all of which are bigger than my particular dissertation:

- to what cultural narratives do these signals & sensors cohere?

- how and why might people consent to giving up their physiological data, to other people versus to other entities? 

-  threats to privacy can be difficult to reason about, but imagining sending these data to your employer or friends is a bit more concrete. can these findings help educate people to be more careful about transmitting these data? to people, or to other (corporate, government) entities? 

as far as concrete offerings to the broader world, i'm hoping for a few discrete outcomes:

- to inform UX design (stakeholder group 1) - so they can create ethical things

- to understand risks to the end user (stakeholder group 2) - so they can reason better about disclosure w/r/t biosignals

- to make ambiguous privacy threats more concrete (threats around disclosure of biosensory data are abstract, far-off, difficult to reason about. it is not so convincing to stay, "someday, our heartrate data may make your insurace rates go up (even though this may well be the case [@latava_longitudinal]). saying, "your heartrate may make you less trustworthy", far more convincing)

- to make a point about the CREEPINESS of this data --- showing that ppl DO make stuff of them, surfacing those meanings in order to draw attention to what sensor companies / economic models are DOING, how they're sucking this data out of you...........


## core refs

### the rise of sensing

pentland

rose

### affective computing

picard

stuff from her book

### social signals

mediator

goffman

donath

moodlight








# back matter

here are some stray lines of argumentation

none are crucial to this first round of feedback, but feel free to peruse them at your leisure

## motivation

<!-- biosensing on the rise -->
<!-- biosensing technologies are becoming pervasive in our daily lives, beyond wristwatches and eyeglasses, into clothing, furniture, mirrors, cars, personal robots, ingestibles. -->
biosensors will enable us to build increasingly high-resolution models of the human physiology, as it exists in the wild, outside of laboratory settings.

<!-- opportunities -->
there are many reasons why we may want to do this....learning about health, behavior, ... 

<!-- risks -->
BUT, the proliferation of biosensors also means that biomedical data will go to many stakeholders who have not previously had access to this type of data. ...
<!-- low barrier to entry w surveillance / anyone can play from home -->
with wearable biosensors specifically, the barrier to entry is low. just order some sensors from adafruit, wire them to an arduino, and start a kickstarter - soon enough, you'll be collecting massive bio-datasets of your own (bio big data, as it were).

<!-- onus on the appication designers -->
application designers are now gatekeepers to a whole new class of potentially highly personal data, the "first line" between these and other users, and of corporate interests........... they could coerce users into giving up that data in a number of ways........essentially coerce users into being surveilled in new and potentially scary ways. users have no idea what the data they give up might mean in the near future, when new analyses find new correlations, with mood, with behavior, with temperment...

meanwhile, forms of consent have a lot to do with the applications offered to user, what they claim to give to users.....






<!-- this is an opportunity and a challenge, for ux designers -->
<!-- for users, its an opportunity and a privacy/security challenge -->

<!-- contest surveillance -->
<!-- raise some alarms -->



## importance

understanding how to protect users in this new context of collection requries understanding and anticipating situations in which users may be tempted to give their data up

this is a big problem, so a slightly smaller thing to interrogate is: what do people MAKE of physiological data? 
and, even more specifically, 
how do people use physiological data to build interpretations about stuff like mood, state of mind?
how do these signals take on SOCIALLY CONTEXTUAL meanings?

here, we examine a special case of disclosure, by seeing what biosignals mean in social contexts.

finally, a few outcomes:

- to inform UX design (stakeholder group 1) - so they can create ethical things

- to understand risks to the end user (stakeholder group 2) - so they can reason better about disclosure w/r/t biosignals

- to make ambiguous privacy threats more concrete (threats around disclosure of biosensory data are abstract, far-off, difficult to reason about. it is not so convincing to stay, "someday, our heartrate data may make your insurace rates go up (even though this may well be the case [@latava_longitudinal]). saying, "your heartrate may make you less trustworthy", far more convincing)

- to make a point about the CREEPINESS of this data --- showing that ppl DO make stuff of them, surfacing those meanings in order to draw attention to what sensor companies / economic models are DOING, how they're sucking this data out of you...........
