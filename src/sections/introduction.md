## motivation

<!-- biosensing on the rise -->
<!-- biosensing technologies are becoming pervasive in our daily lives, beyond wristwatches and eyeglasses, into clothing, furniture, mirrors, cars, personal robots, ingestibles. -->
biosensors will enable us to build increasingly high-resolution models of the human physiology, as it exists in the wild, outside of laboratory settings.

<!-- opportunities -->
there are many reasons why we may want to do this....learning about health, behavior, ... 

<!-- risks -->
BUT, the proliferation of biosensors also means that biomedical data will go to many stakeholders who have not previously had access to this type of data. ...
<!-- low barrier to entry w surveillance / anyone can play from home -->
with wearable biosensors specifically, the barrier to entry is low. just order some sensors from adafruit, wire them to an arduino, and start a kickstarter - soon enough, you'll be collecting massive bio-datasets of your own (bio big data, as it were).

<!-- onus on the appication designers -->
application designers are now gatekeepers to a whole new class of potentially highly personal data, the "first line" between these and other users, and of corporate interests........... they could coerce users into giving up that data in a number of ways........essentially coerce users into being surveilled in new and potentially scary ways. users have no idea what the data they give up might mean in the near future, when new analyses find new correlations, with mood, with behavior, with temperment...

meanwhile, forms of consent have a lot to do with the applications offered to user, what they claim to give to users.....






<!-- this is an opportunity and a challenge, for ux designers -->
<!-- for users, its an opportunity and a privacy/security challenge -->

<!-- contest surveillance -->
<!-- raise some alarms -->


## importance

understanding how to protect users in this new context of collection requries understanding and anticipating situations in which users may be tempted to give their data up

this is a big problem, so a slightly smaller thing to interrogate is: what do people MAKE of physiological data? 
and, even more specifically, 
how do people use physiological data to build interpretations about stuff like mood, state of mind?
how do these signals take on SOCIALLY CONTEXTUAL meanings?

here, we examine a special case of disclosure, by seeing what biosignals mean in social contexts.

### outcomes 

broadly, i'm hoping these findings gesture toward a few interesting questions, all of which are bigger than my particular dissertation:

- to what cultural narratives do these signals & sensors cohere?

- how and why might people consent to giving up their physiological data, to other people versus to other entities? 

-  threats to privacy can be difficult to reason about, but imagining sending these data to your employer or friends is a bit more concrete. can these findings help educate people to be more careful about transmitting these data? to people, or to other (corporate, government) entities? 

as far as concrete offerings to the broader world, i'm hoping for a few discrete outcomes:

- to inform UX design (stakeholder group 1) - so they can create ethical things

- to understand risks to the end user (stakeholder group 2) - so they can reason better about disclosure w/r/t biosignals

- to make ambiguous privacy threats more concrete (threats around disclosure of biosensory data are abstract, far-off, difficult to reason about. it is not so convincing to stay, "someday, our heartrate data may make your insurace rates go up (even though this may well be the case [@latvala_longitudinal_2015]). saying, "your heartrate may make you less trustworthy", far more convincing)

- to make a point about the CREEPINESS of this data --- showing that ppl DO make stuff of them, surfacing those meanings in order to draw attention to what sensor companies / economic models are DOING, how they're sucking this data out of you...........


